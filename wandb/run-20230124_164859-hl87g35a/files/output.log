DDRNetMTL_Split
Dataset: Sim_Warehouse | Training Task: Depth + Semantic + Normals | Primary Task: Depth + Semantic + Normals in Multi-task / Auxiliary Learning Mode with DDRNET
Applying Multi-task Methods: Weighting-based: Equal + Gradient-based: None
STEP. Loading datasets...
Data sanity check. RGB.shape: torch.Size([32, 3, 360, 640]),	Depth.shape torch.Size([32, 1, 360, 640]),        	Semantic.shape torch.Size([32, 1, 720, 1280]),	Normals.shape torch.Size([32, 3, 360, 640])
  0%|                                                                                                            | 0/60 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/robotlabx/mtl-world/train_model.py", line 630, in <module>
    training(opt)
  File "/home/robotlabx/mtl-world/train_model.py", line 335, in training
    train_loss = [compute_loss_ole(opt.data.dataset,train_pred[i], train_target[task_id], task_id) for i, task_id in enumerate(train_tasks)]
  File "/home/robotlabx/mtl-world/train_model.py", line 335, in <listcomp>
    train_loss = [compute_loss_ole(opt.data.dataset,train_pred[i], train_target[task_id], task_id) for i, task_id in enumerate(train_tasks)]
  File "/home/robotlabx/mtl-world/utils.py", line 165, in compute_loss_ole
    semantic_resized = torch.nn.functional.interpolate(gt, size=(360,640), mode='nearest')
  File "/home/robotlabx/anaconda3/envs/multisim/lib/python3.9/site-packages/torch/nn/functional.py", line 3922, in interpolate
    return torch._C._nn.upsample_nearest2d(input, output_size, scale_factors)
RuntimeError: "upsample_nearest2d_out_frame" not implemented for 'Long'