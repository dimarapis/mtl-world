DDRNetMTL_Split
Dataset: Sim_Warehouse | Training Task: Depth + Semantic + Normals | Primary Task: Depth + Semantic + Normals in Multi-task / Auxiliary Learning Mode with DDRNET
Applying Multi-task Methods: Weighting-based: Equal + Gradient-based: None
STEP. Loading datasets...
torch.Size([720, 1280])
Traceback (most recent call last):
  File "/home/robotlabx/mtl-world/train_model.py", line 630, in <module>
    training(opt)
  File "/home/robotlabx/mtl-world/train_model.py", line 272, in training
    train_sample = next(iter(train_loader))
  File "/home/robotlabx/anaconda3/envs/multisim/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/robotlabx/anaconda3/envs/multisim/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/robotlabx/anaconda3/envs/multisim/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/robotlabx/anaconda3/envs/multisim/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/robotlabx/mtl-world/autolambda_code.py", line 203, in __getitem__
    semantic_resized = torch.nn.functional.interpolate(semantic, size=(360,640), mode='interpolate', align_corners=True)
  File "/home/robotlabx/anaconda3/envs/multisim/lib/python3.9/site-packages/torch/nn/functional.py", line 3866, in interpolate
    raise ValueError(
ValueError: Input and output must have the same number of spatial dimensions, but got input with spatial dimensions of [] and output size of (360, 640). Please provide input tensor in (N, C, d1, d2, ...,dK) format and output size in (o1, o2, ...,oK) format.