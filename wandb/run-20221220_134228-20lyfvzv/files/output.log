DDRNetMTL_Split
Dataset: Nyuv2 | Training Task: Semantic + Depth + Normals | Primary Task: Semantic + Depth + Normals in Multi-task / Auxiliary Learning Mode with DDRNET
Applying Multi-task Methods: Weighting-based: Equal + Gradient-based: NONE
STEP. Loading datasets...
Data sanity check. RGB.shape: torch.Size([32, 3, 288, 384]),	Depth.shape torch.Size([32, 1, 288, 384]),    	Semantic.shape torch.Size([32, 288, 384]),	Normals.shape torch.Size([32, 3, 288, 384])
  0%|                                                                                                                                                         | 0/25 [00:00<?, ?it/s]/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode)


100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:07<00:00,  3.38it/s]
train_model.py:290: RuntimeWarning: invalid value encountered in true_divide
  depth = (depth - np.min(depth)) / (np.max(depth) - np.min(depth))
Traceback (most recent call last):
  File "train_model.py", line 405, in <module>
    gt_normals = rgb_visualizer(multitaskdatatest['normals'].to(device).squeeze(1).squeeze(0).cpu().numpy())
  File "train_model.py", line 301, in rgb_visualizer
    rgb = np.transpose(image, (1, 2, 0))
  File "<__array_function__ internals>", line 6, in transpose
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/numpy/core/fromnumeric.py", line 658, in transpose
    return _wrapfunc(a, 'transpose', axes)
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/numpy/core/fromnumeric.py", line 58, in _wrapfunc
    return bound(*args, **kwds)
ValueError: axes don't match array
tensor([[[[ 9.6086e-02,  4.1844e-01,  7.4080e-01,  ...,  1.7904e+00,
            1.7966e+00,  1.8028e+00],
          [ 1.6435e-01,  4.4670e-01,  7.2905e-01,  ...,  1.7907e+00,
            1.8118e+00,  1.8328e+00],
          [ 2.3262e-01,  4.7496e-01,  7.1730e-01,  ...,  1.7911e+00,
            1.8269e+00,  1.8627e+00],
          ...,
          [-1.2049e-03,  7.0685e-02,  1.4258e-01,  ...,  1.2470e-01,
            9.7993e-02,  7.1288e-02],
          [ 4.0576e-02,  1.0534e-01,  1.7010e-01,  ...,  2.1831e-01,
            1.6904e-01,  1.1977e-01],
          [ 8.2357e-02,  1.3999e-01,  1.9762e-01,  ...,  3.1192e-01,
            2.4009e-01,  1.6825e-01]],
         [[-1.0705e+00, -9.1326e-01, -7.5602e-01,  ..., -2.4642e+00,
           -2.3386e+00, -2.2129e+00],
          [-1.2067e+00, -1.0573e+00, -9.0790e-01,  ..., -2.4675e+00,
           -2.3398e+00, -2.2122e+00],
          [-1.3429e+00, -1.2013e+00, -1.0598e+00,  ..., -2.4707e+00,
           -2.3411e+00, -2.2115e+00],
          ...,
          [-2.0806e+00, -2.0456e+00, -2.0106e+00,  ..., -1.0110e+00,
           -8.0554e-01, -6.0005e-01],
          [-2.1032e+00, -2.0597e+00, -2.0162e+00,  ..., -9.7704e-01,
           -7.2200e-01, -4.6697e-01],
          [-2.1258e+00, -2.0738e+00, -2.0218e+00,  ..., -9.4305e-01,
           -6.3846e-01, -3.3388e-01]],
         [[-1.0200e+00, -9.3505e-01, -8.5006e-01,  ..., -1.2692e+00,
           -1.4833e+00, -1.6974e+00],
          [-9.1460e-01, -8.3842e-01, -7.6223e-01,  ..., -1.1576e+00,
           -1.3508e+00, -1.5439e+00],
          [-8.0916e-01, -7.4178e-01, -6.7439e-01,  ..., -1.0460e+00,
           -1.2182e+00, -1.3904e+00],
          ...,
          [ 4.5302e-01,  4.4827e-01,  4.4351e-01,  ..., -1.5992e+00,
           -1.6077e+00, -1.6161e+00],
          [ 6.3074e-01,  6.3508e-01,  6.3942e-01,  ..., -1.7011e+00,
           -1.6724e+00, -1.6437e+00],
          [ 8.0847e-01,  8.2190e-01,  8.3533e-01,  ..., -1.8030e+00,
           -1.7371e+00, -1.6713e+00]]]], device='cuda:0')